{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b809fc7",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f984e3",
   "metadata": {
    "id": "00f984e3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier,OneVsOneClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211033fc",
   "metadata": {
    "id": "211033fc"
   },
   "source": [
    "## 1. High Dimensional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b5ba44",
   "metadata": {
    "id": "98b5ba44"
   },
   "outputs": [],
   "source": [
    "## loading the data\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa45db96",
   "metadata": {
    "id": "aa45db96"
   },
   "outputs": [],
   "source": [
    "#reading the data\n",
    "data = fetch_20newsgroups_vectorized()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pBrsMYsnBeCB",
   "metadata": {
    "id": "pBrsMYsnBeCB"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HK2qTmsNB6So",
   "metadata": {
    "id": "HK2qTmsNB6So"
   },
   "source": [
    "#### Logistic Regression OnevsRest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "UvN8SoPJBrfe",
   "metadata": {
    "id": "UvN8SoPJBrfe"
   },
   "outputs": [],
   "source": [
    "log_reg_ovr = OneVsRestClassifier(LogisticRegression()).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "AI4OH34MCpPD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AI4OH34MCpPD",
    "outputId": "34bfd22c-d8ca-4c8a-b2ce-80ba9ada2141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression One vs Rest Algorithm is 0.7998232434821034\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test set\n",
    "print('The accuracy of Logistic Regression One vs Rest Algorithm is',accuracy_score(y_test,log_reg_ovr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5j-30SlaDlaT",
   "metadata": {
    "id": "5j-30SlaDlaT"
   },
   "source": [
    "#### Logistic Regression OnevsOne Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "La30M2L5DjJf",
   "metadata": {
    "id": "La30M2L5DjJf"
   },
   "outputs": [],
   "source": [
    "log_reg_ovo = OneVsOneClassifier(LogisticRegression()).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "BTk5p9haDi8K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTk5p9haDi8K",
    "outputId": "c189dbc5-1aa7-4c4b-d8b5-0cb5cefdae25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression One vs One Algorithm is 0.7220503756076005\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test set\n",
    "print('The accuracy of Logistic Regression One vs One Algorithm is',accuracy_score(y_test,log_reg_ovo.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fWfrMYoFjaq",
   "metadata": {
    "id": "1fWfrMYoFjaq"
   },
   "source": [
    "#### LDA OnevsRest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oq_w4QUyQQkG",
   "metadata": {
    "id": "oq_w4QUyQQkG"
   },
   "outputs": [],
   "source": [
    "#To restrict getting out of memory error reduce the dimensions of our data by SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tYbc1W_N-iIY",
   "metadata": {
    "id": "tYbc1W_N-iIY"
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=700)\n",
    "X_train_reduced = svd.fit_transform(X_train)\n",
    "X_test_reduced = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "w1gM9ae0Fqle",
   "metadata": {
    "id": "w1gM9ae0Fqle"
   },
   "outputs": [],
   "source": [
    "lda_ovr = OneVsRestClassifier(LinearDiscriminantAnalysis()).fit(X_train_reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "952SfezRFpy7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "952SfezRFpy7",
    "outputId": "1b919746-d80a-4f06-d3ab-8bfaf57a1bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of LDA One vs Rest Algorithm is 0.821917808219178\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test set\n",
    "print('The accuracy of LDA One vs Rest Algorithm is',accuracy_score(y_test,lda_ovr.predict(X_test_reduced)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JdpRQMkdXppr",
   "metadata": {
    "id": "JdpRQMkdXppr"
   },
   "source": [
    "#### LDA OnevsOne Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5OJMY1J-DieD",
   "metadata": {
    "id": "5OJMY1J-DieD"
   },
   "outputs": [],
   "source": [
    "lda_ovo = OneVsOneClassifier(LinearDiscriminantAnalysis()).fit(X_train_reduced,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "Mb85IBTNBpOP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mb85IBTNBpOP",
    "outputId": "5c2ca52c-daad-4463-cf8f-6dc84fe81dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of LDA One vs Rest Algorithm is 0.6827220503756076\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test set\n",
    "print('The accuracy of LDA One vs Rest Algorithm is',accuracy_score(y_test,lda_ovo.predict(X_test_reduced)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d4493",
   "metadata": {
    "id": "319d4493"
   },
   "source": [
    "## 2. Variable Selection via Forward and Backward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af707c2a",
   "metadata": {
    "id": "af707c2a"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8f6dc",
   "metadata": {
    "id": "8ad8f6dc"
   },
   "source": [
    "Making the Function for Forward and Backward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6baced9f",
   "metadata": {
    "id": "6baced9f"
   },
   "outputs": [],
   "source": [
    "def forward_search(x,y_train,x_valid,y_valid, model,show = True):\n",
    "    good_features = set() #set to store the values of the features that are good for the model\n",
    "    good_list = [] #list for convenient indexing\n",
    "    loss_with_good_features = [] #list to store loss after adding each variable\n",
    "    n = -1\n",
    "\n",
    "    all_cols = set(np.arange(x.shape[1]))\n",
    "\n",
    "    while n<x.shape[1]-1:\n",
    "        error_dict = {}\n",
    "        error_dict_train = {}\n",
    "        n += 1\n",
    "        active_cols = all_cols.difference(good_features)\n",
    "        #iterate over all features and add them one by one\n",
    "        for col in active_cols:\n",
    "\n",
    "            cols = list(good_features.union(set({col})))\n",
    "            fx = x[:,cols] #i-th feature with good features\n",
    "\n",
    "            #fit the model\n",
    "            if n == 0:\n",
    "                model.fit(fx.reshape(-1,1),y_train)\n",
    "            else:\n",
    "                model.fit(fx,y_train)\n",
    "\n",
    "            #test it\n",
    "            preds = model.predict(x_valid[:,cols])\n",
    "            err = mean_squared_error(y_valid,preds)\n",
    "\n",
    "            #append the error after adding all the columns\n",
    "            error_dict[col] = err\n",
    "            error_dict_train[col] = mean_squared_error(y_train,model.predict(x[:,cols]))\n",
    "\n",
    "        #get the column which has the lowest error\n",
    "        good_feature = min(error_dict, key=error_dict.get)\n",
    "\n",
    "        #store the corresponding value\n",
    "        loss_with_good_features.append(error_dict[good_feature])\n",
    "\n",
    "        #make history of good features\n",
    "        good_features.add(good_feature)\n",
    "        good_list.append(good_feature)\n",
    "        \n",
    "        if show:\n",
    "            print('Currently Selected Variables',good_features)\n",
    "            print('The Training Loss is',error_dict_train[good_feature],'The Testing Loss is',error_dict[good_feature],'\\n')\n",
    "        \n",
    "    return good_list[:np.argmin(loss_with_good_features)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b3a636d",
   "metadata": {
    "id": "6b3a636d"
   },
   "outputs": [],
   "source": [
    "def backward_search(x,y_train,x_valid,y_valid,model,show=True):\n",
    "    bad_features = set() #set to store the values of the features that are good for the model\n",
    "    bad_list = [] #list for convenient indexing\n",
    "    loss_without_bad_features = [] #list to store loss after adding each variable\n",
    "    n = 0\n",
    "    all_cols = set(np.arange(x.shape[1]))\n",
    "\n",
    "    while n<x.shape[1]-1:\n",
    "        error_dict = {}\n",
    "        error_dict_train = {}\n",
    "        n += 1\n",
    "        active_cols = all_cols.difference(bad_features)\n",
    "        #iterate over all features and add them one by one\n",
    "        for col in active_cols:\n",
    "\n",
    "            cols = list(active_cols.difference(set({col})))\n",
    "            fx = x[:,cols] #without i-th feature\n",
    "\n",
    "            #fit the model\n",
    "            if n == x.shape[1]:\n",
    "                model.fit(fx.reshape(-1,1),y_train)\n",
    "            else:\n",
    "                model.fit(fx,y_train)\n",
    "\n",
    "            #test it\n",
    "            preds = model.predict(x_valid[:,cols])\n",
    "            err = mean_squared_error(y_valid,preds)\n",
    "\n",
    "            #append the error after adding all the columns\n",
    "            error_dict[col] = err\n",
    "            error_dict_train[col] = mean_squared_error(y_train,model.predict(x[:,cols]))\n",
    "\n",
    "        #get the column which has the lowest error\n",
    "        bad_feature = min(error_dict, key=error_dict.get)\n",
    "\n",
    "        #store the corresponding value\n",
    "        loss_without_bad_features.append(error_dict[bad_feature])\n",
    "\n",
    "        #make history of good features\n",
    "        bad_features.add(bad_feature)\n",
    "        bad_list.append(bad_feature)\n",
    "\n",
    "        if show:\n",
    "            print('Currently Selected Variables',active_cols.difference(bad_features))\n",
    "            print('The Training Loss is',error_dict_train[bad_feature],'The Testing Loss is',error_dict[bad_feature],'\\n')\n",
    "    features = np.delete(list(all_cols),bad_list[:np.argmin(loss_without_bad_features)+1])    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea23f355",
   "metadata": {
    "id": "ea23f355"
   },
   "outputs": [],
   "source": [
    "# reading the data\n",
    "with open('regression.npy', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "    y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39faba13",
   "metadata": {
    "id": "39faba13"
   },
   "outputs": [],
   "source": [
    "#splitting into trianing and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9OmV3NAkHQ45",
   "metadata": {
    "id": "9OmV3NAkHQ45"
   },
   "outputs": [],
   "source": [
    "#initialize Least Angle Regression Model\n",
    "least_angle_regression = Lars(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45e7dddf",
   "metadata": {
    "id": "45e7dddf"
   },
   "outputs": [],
   "source": [
    "bf = forward_search(X_train,y_train,X_test,y_test,least_angle_regression,False) ##unsorted list of features based on importance\n",
    "best_features_via_forward_search = sorted(bf)\n",
    "best_features_via_backward_search = backward_search(X_train,y_train,X_test,y_test,least_angle_regression,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "888c0b64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "888c0b64",
    "outputId": "af8fc25e-e58f-4f49-918c-5465dbce3cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see if the result of forward and backward search is same\n",
    "np.all(best_features_via_backward_search == best_features_via_forward_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "Xa0cROKquyO9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xa0cROKquyO9",
    "outputId": "ac257bf9-167a-4c05-b935-891123e0e2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices of the selected features are\n",
      "[ 0  1  3  4  8  9 11 12 13 17 19 24 27 32 33 35 37 38 40 48 51 55 58 59\n",
      " 60 61 62 64 65 68 69 71 83 84 90 92 93 94 95] \n",
      "\n",
      "The error produced by the feature selection model LARS is: 5.994330195060494\n"
     ]
    }
   ],
   "source": [
    "##to see what are those features\n",
    "print('The indices of the selected features are')\n",
    "print(best_features_via_backward_search,'\\n')\n",
    "\n",
    "##to fit a model using those features\n",
    "least_angle_regression = Lars(normalize=False)\n",
    "least_angle_regression.fit(X_train[:,best_features_via_backward_search],y_train)\n",
    "##the error produced by the features selected through feature selection\n",
    "print('The error produced by the feature selection model LARS is:',mean_squared_error(y_test,least_angle_regression.predict(X_test[:,best_features_via_backward_search])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db312cbf",
   "metadata": {
    "id": "db312cbf"
   },
   "source": [
    "## 3. Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QUIPhvSdEnlM",
   "metadata": {
    "id": "QUIPhvSdEnlM"
   },
   "source": [
    "**Small and Large Value of Alpha:**\n",
    "If the value of alpha is very high, the regularization term will overpower the loss function and the model would just learn to optimize on the regularization term. This would not result in any fruitful model training (chances of underfitting). On the other hand if the value of alpha is very low, the model will ignore the regularization and instead weigh more the optimization of the cost function itself, which would be close to having no regularization as in simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adfcc21b",
   "metadata": {
    "id": "adfcc21b"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,ElasticNet,Lasso\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3deb057a",
   "metadata": {
    "id": "3deb057a"
   },
   "outputs": [],
   "source": [
    "#initialize ridge, lasso and elastic net model\n",
    "ridge = Ridge()\n",
    "elastic_net = ElasticNet()\n",
    "lasso = Lasso()\n",
    "clf_list = [ridge,elastic_net,lasso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e473e82",
   "metadata": {
    "id": "5e473e82"
   },
   "outputs": [],
   "source": [
    "#param grid with different values of alpha\n",
    "params = {'alpha':[10,1,0.1,0.0001,0.00001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14e6724a",
   "metadata": {
    "id": "14e6724a"
   },
   "outputs": [],
   "source": [
    "best_models = []\n",
    "best_errors = []\n",
    "best_estimators = []\n",
    "for clf in clf_list:\n",
    "    #run grid search\n",
    "    grid_search = GridSearchCV(clf,param_grid=params,scoring='neg_mean_squared_error',cv=5,refit=True)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    best_models.append(grid_search)\n",
    "    best_estimators.append(np.array(grid_search.best_estimator_))\n",
    "    best_errors.append(grid_search.best_score_)\n",
    "    \n",
    "    #run random search\n",
    "    random_search = RandomizedSearchCV(clf,params,scoring='neg_mean_squared_error',cv=5,refit=True,n_iter=3)\n",
    "    random_search.fit(X_train,y_train)\n",
    "    best_models.append(random_search)\n",
    "    best_estimators.append(np.array(random_search.best_estimator_))\n",
    "    best_errors.append(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0af6b15d",
   "metadata": {
    "id": "0af6b15d"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(best_models,columns=['models'])\n",
    "results['errors'] = best_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c38fb82",
   "metadata": {
    "id": "5c38fb82"
   },
   "outputs": [],
   "source": [
    "results['estimators'] = results['models'].apply(lambda x: np.array(x.estimator))\n",
    "results['alpha'] = results['models'].apply(lambda x:x.best_params_['alpha'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "gMv9w5M-5kun",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "gMv9w5M-5kun",
    "outputId": "d3872b71-a30e-418c-ad90-2301f1fce47b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-82b19178-5b03-4cda-919d-ed6c53495e43\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>errors</th>\n",
       "      <th>estimators</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GridSearchCV(cv=5, estimator=Lasso(),\\n       ...</td>\n",
       "      <td>-5.963695</td>\n",
       "      <td>Lasso()</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomizedSearchCV(cv=5, estimator=Lasso(), n_...</td>\n",
       "      <td>-5.963695</td>\n",
       "      <td>Lasso()</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GridSearchCV(cv=5, estimator=ElasticNet(),\\n  ...</td>\n",
       "      <td>-5.964449</td>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV(cv=5, estimator=Ridge(),\\n       ...</td>\n",
       "      <td>-5.965118</td>\n",
       "      <td>Ridge()</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomizedSearchCV(cv=5, estimator=Ridge(), n_...</td>\n",
       "      <td>-5.965118</td>\n",
       "      <td>Ridge()</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomizedSearchCV(cv=5, estimator=ElasticNet(...</td>\n",
       "      <td>-5.965309</td>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82b19178-5b03-4cda-919d-ed6c53495e43')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-82b19178-5b03-4cda-919d-ed6c53495e43 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-82b19178-5b03-4cda-919d-ed6c53495e43');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              models    errors    estimators  \\\n",
       "4  GridSearchCV(cv=5, estimator=Lasso(),\\n       ... -5.963695       Lasso()   \n",
       "5  RandomizedSearchCV(cv=5, estimator=Lasso(), n_... -5.963695       Lasso()   \n",
       "2  GridSearchCV(cv=5, estimator=ElasticNet(),\\n  ... -5.964449  ElasticNet()   \n",
       "0  GridSearchCV(cv=5, estimator=Ridge(),\\n       ... -5.965118       Ridge()   \n",
       "1  RandomizedSearchCV(cv=5, estimator=Ridge(), n_... -5.965118       Ridge()   \n",
       "3  RandomizedSearchCV(cv=5, estimator=ElasticNet(... -5.965309  ElasticNet()   \n",
       "\n",
       "     alpha  \n",
       "4  0.00010  \n",
       "5  0.00010  \n",
       "2  0.00010  \n",
       "0  1.00000  \n",
       "1  1.00000  \n",
       "3  0.00001  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='errors',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j_ZgDbCi6-NV",
   "metadata": {
    "id": "j_ZgDbCi6-NV"
   },
   "source": [
    "**Top 3 Models:** here we can see that the Lasso with 0.0001 alpha value, ElasticNet with 0.0001 alpha value and Ridge with alpha value of 1 are top three models\n",
    "\n",
    "**Comparision with Q2:** Also, One more thing we can observe is these models are slightly better than the one we obtained through backward and forward search. That model gave MSE = 5.99 however the top 3 regularized models give error of 5.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K68UE_3IKqor",
   "metadata": {
    "id": "K68UE_3IKqor"
   },
   "source": [
    "Let's obtain the Top K indices of these three models and compare them with the ones obtained through forward search and LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "RxCExr6DGCeD",
   "metadata": {
    "id": "RxCExr6DGCeD"
   },
   "outputs": [],
   "source": [
    "r = Ridge(alpha=1)\n",
    "l = Lasso(alpha=0.0001)\n",
    "e = ElasticNet(alpha=0.0001)\n",
    "best_three_models = [r,l,e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "x8-G3N7WxVZ2",
   "metadata": {
    "id": "x8-G3N7WxVZ2"
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "for m in best_three_models:\n",
    "    indices.append(forward_search(X_train,y_train,X_test,y_test,m,False)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0EaWjKMEOEq2",
   "metadata": {
    "id": "0EaWjKMEOEq2"
   },
   "source": [
    "Let's see if the top K indices of best three models are same as LARS model in Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "XzLz8YUmM4V6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XzLz8YUmM4V6",
    "outputId": "2fc171e4-a7b5-492d-a677-b597c0b64047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current K is 1\n",
      "True\n",
      "The current K is 2\n",
      "True\n",
      "The current K is 3\n",
      "True\n",
      "The current K is 4\n",
      "True\n",
      "The current K is 5\n",
      "True\n",
      "The current K is 6\n",
      "True\n",
      "The current K is 7\n",
      "True\n",
      "The current K is 8\n",
      "False\n",
      "The current K is 9\n",
      "False\n",
      "The current K is 10\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "## trying out bunch of K return True if the the value of all three models is same as Q2 model\n",
    "for k in range(1,11):\n",
    "    print('The current K is',k)\n",
    "    same = []\n",
    "    tk_l = bf[:k]\n",
    "    ## compairing with top K indices of LARS model\n",
    "    for ind in indices:\n",
    "    same.append(np.all(ind[:k] == tk_l))\n",
    "    print(np.all(same))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vRZul4pcO9GW",
   "metadata": {
    "id": "vRZul4pcO9GW"
   },
   "source": [
    "Upto K=7 the indices are same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4448d0",
   "metadata": {
    "id": "6e4448d0"
   },
   "source": [
    "## 4. Custom Linear Regression Using Inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc39ef9",
   "metadata": {
    "id": "0cc39ef9"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc020273",
   "metadata": {
    "id": "dc020273"
   },
   "outputs": [],
   "source": [
    "class MyLinearRegression(BaseEstimator,RegressorMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #check if the shape of X and y is correct\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        x_bar = np.mean(X,axis=0) # calculate mean of x\n",
    "        y_bar = np.mean(y,axis=0) # calculate mean of y\n",
    "\n",
    "        # for calculating B1\n",
    "        B1 = np.divide(np.sum(np.multiply((X-x_bar),(y-y_bar).reshape(-1,1)),axis=0,keepdims=True),np.sum(np.square(X-x_bar),axis=0,keepdims=True))\n",
    "\n",
    "        # for calculating B0\n",
    "        B0 = y_bar - B1.reshape(1,-1)@x_bar.reshape(-1,1)\n",
    "        \n",
    "        self.coef_ = B1.T\n",
    "        self.intercept_ = B0\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        return np.ravel(X@self.coef_ + self.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ebf5a7",
   "metadata": {
    "id": "a8ebf5a7"
   },
   "outputs": [],
   "source": [
    "#making the data\n",
    "X = np.arange(0,5.5,0.5)\n",
    "y = np.array([6.0,4.83,3.7,3.15,2.41,1.83,1.49,1.21,0.96,0.73,0.64])\n",
    "\n",
    "#splitting into trianing and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30134424",
   "metadata": {
    "id": "30134424",
    "outputId": "67b8dd5a-b936-4ba2-9027-9835b58ed190"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MyLinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MyLinearRegression</label><div class=\"sk-toggleable__content\"><pre>MyLinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MyLinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "linear_reg = MyLinearRegression()\n",
    "linear_reg.fit(X_train.reshape(-1,1),y_train) ## reshaping to avoid the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9986a38",
   "metadata": {
    "id": "b9986a38"
   },
   "outputs": [],
   "source": [
    "## to check if the estimator is valid\n",
    "check_estimator(MyLinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a2db06",
   "metadata": {
    "id": "b9a2db06",
    "outputId": "9b28bd8b-d97b-42c8-dfe3-b0047d8f6c09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7237418923740918"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##predicting on test set\n",
    "preds = linear_reg.predict(X_test.reshape(-1,1))\n",
    "mean_squared_error(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821390c5",
   "metadata": {
    "id": "821390c5",
    "outputId": "b568cd00-218a-4f78-8b6a-620b291a7014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of B0 is [[4.63811252]]\n",
      "The value of B1 is [[-0.91292196]]\n"
     ]
    }
   ],
   "source": [
    "##print the value of B0 and B1\n",
    "print('The value of B0 is',linear_reg.intercept_)\n",
    "print('The value of B1 is',linear_reg.coef_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
